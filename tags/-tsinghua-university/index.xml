<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Tsinghua University on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-tsinghua-university/</link><description>Recent content in üè¢ Tsinghua University on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Mon, 04 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-tsinghua-university/index.xml" rel="self" type="application/rss+xml"/><item><title>DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/</guid><description>DeeR-VLA dynamically adjusts the size of a multimodal large language model based on task difficulty, significantly reducing computational cost and memory usage in robotic control without compromising &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02359/cover.png"/></item><item><title>Sparsing Law: Towards Large Language Models with Greater Activation Sparsity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02335/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02335/</guid><description>Researchers discovered predictable scaling laws for activation sparsity in LLMs, showing how data, architecture, and model size influence sparsity, paving the way for more efficient and interpretable &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02335/cover.png"/></item><item><title>WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02337/</link><pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02337/</guid><description>WEBRL: A self-evolving online curriculum reinforcement learning framework empowers open LLMs to excel as high-performing web agents, surpassing proprietary models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2411.02337/cover.png"/></item><item><title>AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24024/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24024/</guid><description>ANDROIDLAB, a novel framework, systematically benchmarks Android autonomous agents, improving LLM and LMM success rates on 138 tasks via a unified environment and open-source dataset.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24024/cover.png"/></item><item><title>Constraint Back-translation Improves Complex Instruction Following of Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24175/</link><pubDate>Thu, 31 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24175/</guid><description>Constraint Back-translation enhances complex instruction following in LLMs by leveraging inherent constraints in existing datasets for efficient high-quality data creation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.24175/cover.png"/></item></channel></rss>